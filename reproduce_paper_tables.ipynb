{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from config import data_dir\n",
    "import os \n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\PC-1\\\\PycharmProjects\\\\mdtel'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = ['diabetes', 'sclerosis', 'depression']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3: Medical term mentions in 100 posts for 3 OHC Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Relevant Medical Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>3881</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclerosis</th>\n",
       "      <td>8687</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depression</th>\n",
       "      <td>8106</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Words  Relevant Medical Terms\n",
       "diabetes     3881                     477\n",
       "sclerosis    8687                     611\n",
       "depression   8106                     716"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manually_labeled_dir = data_dir + 'manual_labeled'\n",
    "\n",
    "all_res = []\n",
    "\n",
    "for comm in communities:\n",
    "    comm_path = manually_labeled_dir + os.sep + comm + \".xlsx\"\n",
    "    comm_df = pd.read_excel(comm_path)\n",
    "    comm_df = comm_df[~comm_df['manual_tag'].isna()]\n",
    "    \n",
    "    comm_df['tokenized_txt_words'] = comm_df['tokenized_txt'].apply(lambda x: x.split(\" \"))\n",
    "    comm_df['tokenized_txt_words'].apply(lambda lst: [w.translate(table) for w in lst])\n",
    "    \n",
    "    all_words = []\n",
    "\n",
    "    for words in comm_df['tokenized_txt_words'].values:\n",
    "        all_words += words\n",
    "    all_words_num = sum(Counter(all_words).values())\n",
    "    \n",
    "    comm_df['manual_tag_lst'] = comm_df['manual_tag'].apply(lambda x: [y.strip() for y in x.split(',')])\n",
    "    all_med_terms = []\n",
    "    for lst in comm_df['manual_tag_lst'].values: \n",
    "        all_med_terms += lst\n",
    "    relevant_med_terms = sum(Counter(all_med_terms).values())\n",
    "    all_res.append({'Words': all_words_num, 'Relevant Medical Terms': relevant_med_terms})\n",
    "    \n",
    "test_set_stats = pd.DataFrame(all_res, index=communities, columns=['Words', 'Relevant Medical Terms'])\n",
    "test_set_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4: MDTEL UMLS Entity Linking Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got data_dir: E:\\mdtel_data\\data\\\n",
      "            f1_score  roc_auc  recall   acc\n",
      "diabetes        0.89     0.90    0.99  0.85\n",
      "sclerosis       0.85     0.90    0.88  0.85\n",
      "depression      0.79     0.89    0.88  0.81\n"
     ]
    }
   ],
   "source": [
    "!python src\\contextual_relevance\\evaluate_contextual_relevance_model.py $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + r\"contextual_relevance\\output_models\\trained_models.pickle\", 'rb') as f:\n",
    "    trained_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating High-recall candidates filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {comm: trained_models[comm]['confusion_matrix'] for comm in communities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetes': array([[31, 16],\n",
       "        [ 1, 66]], dtype=int64), 'sclerosis': array([[95, 21],\n",
       "        [12, 92]], dtype=int64), 'depression': array([[79, 25],\n",
       "        [ 8, 61]], dtype=int64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of high recall candidates is the sum of all elements in the confusion matrix. \n",
    "Some are indeed medical terms, and some are not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_high_recall_candidates = {comm: sum(sum(trained_models[comm]['confusion_matrix'])) for comm in communities}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of high recall candidates filtered our, is the left column - the column of the terms predicted as \"Negative\" - not a medical terms. \n",
    "Here as well, part of this terms are indeed not medical terms (TN), and some are mistakes (FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_recall_candidates_filtered_out_num = {comm: sum(trained_models[comm]['confusion_matrix'][:, 0]) for comm in communities}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of the filtered our, is the number of high candidates filtered out (predicted as \"Negatives\") divided by the number of high recall candidates (Sum of the confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_recall_candidates_filtered_out = {str(round(high_recall_candidates_filtered_out_num[comm]/number_of_high_recall_candidates[comm]*100, 2)) + \"%\" for comm in communities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_recall_candidates_filtered_out_col = pd.DataFrame(high_recall_candidates_filtered_out, columns=['High-recall candidates filtered out'], index=communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High-recall candidates filtered out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>48.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclerosis</th>\n",
       "      <td>50.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depression</th>\n",
       "      <td>28.07%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           High-recall candidates filtered out\n",
       "diabetes                                48.64%\n",
       "sclerosis                               50.29%\n",
       "depression                              28.07%"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_recall_candidates_filtered_out_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy full algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_high_recall_candidates_series = pd.Series(number_of_high_recall_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes      3881\n",
       "sclerosis     8687\n",
       "depression    8106\n",
       "Name: Words, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_stats['Words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculating additional true negatives.\n",
    "Those are all of the words there weren't candidate as high recall list. \n",
    "They are true negative because they didn't appear in the confusion matrix, therefore they are not misclassified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diabetes      3767\n",
       "sclerosis     8467\n",
       "depression    7933\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_true_negatives = test_set_stats['Words'] - number_of_high_recall_candidates_series\n",
    "additional_true_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetes': 3798, 'sclerosis': 8562, 'depression': 8012}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_alg_true_pos = {comm: cms[comm][0][0] + additional_true_negatives[comm] for comm in communities}\n",
    "full_alg_true_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now inserting the true number of true negatives into the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comm in cms:\n",
    "    cms[comm][0][0] = full_alg_true_pos[comm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc_full_alg_for_cms_and_comm(cms, comm):\n",
    "    tn = cms[comm][0][0]\n",
    "    tp = cms[comm][1][1]\n",
    "    negatives = sum(cms[comm][0])\n",
    "    positives = sum(cms[comm][1])\n",
    "    acc = (tn + tp) / (negatives + positives)\n",
    "    acc = str(round(acc * 100, 2)) + \"%\"\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculating 'Accuracy Full algorithm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Full Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>99.56%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclerosis</th>\n",
       "      <td>99.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depression</th>\n",
       "      <td>99.59%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy Full Algorithm\n",
       "diabetes                    99.56%\n",
       "sclerosis                   99.62%\n",
       "depression                  99.59%"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_full_alg = {comm: calculate_acc_full_alg_for_cms_and_comm(cms, comm) for comm in communities}\n",
    "acc_full_alg_df = pd.DataFrame(accuracy_full_alg.values(), columns=['Accuracy Full Algorithm'], index=communities)\n",
    "acc_full_alg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasEnv36",
   "language": "python",
   "name": "kerasenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
